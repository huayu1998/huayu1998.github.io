{
  "hash": "a42b368886b037a4ea799b25d489bd3f",
  "result": {
    "markdown": "---\ntitle: \"Classification\"\nauthor: \"Huayu Liang\"\ndate: \"now\"\ncategories: [ML, visualization, classification]\nimage: \"classification.png\"\n---\n\nImage from the source: [Analytics Yogi: K-Nearest Neighbors (KNN) Python Examples](https://vitalflux.com/k-nearest-neighbors-explained-with-python-examples/)\n\n# Exploring Classification Algorithms with Python\n\n## What is Classification?\n\nThe Classification algorithm, as a [Supervised Learning](https://en.wikipedia.org/wiki/Supervised_learning) technique, is employed to categorize new observations based on the knowledge gained from training data. In the classification process, the program utilizes a provided dataset or observations to learn how to assign new observations to distinct classes or groups, such as 0 or 1, red or blue, yes or no, spam or not spam, and so on. Terms like targets, labels, or categories are used interchangeably to denote these classes. As a supervised learning technique, the Classification algorithm requires labeled input data, encompassing both input and output information. The classification process involves transferring a discrete output function $f(y)$ to an input variable $(x)$.\n\nIn simpler terms, classification serves as a form of pattern recognition, wherein classification algorithms analyze training data to identify similar patterns in new datasets.\n\n## Iris Dataset Visualization in Machine Learning\n\n### 1. Python Libraries\n\nBefore we dive into classification algorithms, we need to set up our environment. We'll be using the following (main) Python libraries:\n\n-   **`scikit-learn`**: This library provides a wide range of tools for building machine learning models.\n\n-   **`matplotlib`** and **`seaborn`**: These libraries will help us create visualizations.\n\n### 2. Dataset\n\nFor this demonstration, we will use the famous Iris dataset, which contains samples of three different species of iris flowers. The goal is to classify each sample into one of these species.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import load_iris\n\ndata = load_iris()\nX = data.data\ny = data.target\n```\n:::\n\n\n### 3. Visualizing the Data\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.scatterplot(x=X[:, 0], y=X[:, 1], hue=data.target_names[y])\nplt.xlabel(data.feature_names[0])\nplt.ylabel(data.feature_names[1])\nplt.title(\"Iris Dataset: Sepal Length vs Sepal Width\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=589 height=449}\n:::\n:::\n\n\nThis plot shows the separation of iris flowers based on their sepal length and sepal width.\n\n## Types of Classification Algorithms\n\nVarious classification methods can be employed depending on the characteristics of the dataset under consideration. This variability stems from the extensive nature of the study of classification in statistics. Below lists the common four machine learning algorithms.\n\n### 1. Naive Bayes\n\nAs a popular supervised machine learning algorithm, Naïve Bayes classifier is used for classification tasks such as text classification. It belongs to the family of generative learning algorithms, which means that it models the distribution of inputs for a given class or category. This modeling relies on the assumption that, given the class, the features of the input data are conditionally independent, facilitating swift and accurate predictions.\n\nIn statistics, Naïve Bayes classifiers are considered as simple probabilistic classifiers that apply Bayes' theorem. This theorem is based on the probability of a hypothesis, given the data. The Naïve Bayes classifier makes the simplifying assumption that all features in the input data are independent, a condition not always met in practical scenarios. Nevertheless, despite this simplification, the naive Bayes classifier is extensively employed due to its efficiency and commendable performance across various real-world applications.\n\n#### 1.1 Ma**thematical Formulation**\n\nBayes theorem provides a way of computing posterior probability $P(c|x)$ from $P(c)$, $P(x)$ and $P(x|c)$. Look at the equation below\n\n$$\nP(c | x) = \\frac{P(x | c) P(c)}{P(x)}\n$$\n\nWhere,\n\n-   $P(c|x)$ is the posterior probability of *class* (c, *target*) given *predictor* (x, *attributes*).\n\n-   $P(c)$ is the prior probability of *class*.\n\n-   $P(x|c)$ is the likelihood which is the probability of the *predictor* given *class*.\n\n-   $P(x)$ is the prior probability of the *predictor*.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the Gaussian Naive Bayes classifier\nnaive_bayes_classifier = GaussianNB()\n\n# Train the classifier\nnaive_bayes_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = naive_bayes_classifier.predict(X_test)\n\n# Evaluate the classifier's performance\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\n# Display results\nprint(f'Accuracy: {accuracy:.2f}\\n')\nprint('Confusion Matrix:')\nprint(conf_matrix)\nprint('\\nClassification Report:')\nprint(classification_rep)\n\n# Visualize the decision boundary (2D projection for simplicity)\nplt.figure(figsize=(8, 6))\n\n# Plot training points\nfor i, c in zip(range(3), ['maroon', 'orange', 'magenta']):\n    plt.scatter(X_train[y_train == i, 0], X_train[y_train == i, 1], c=c, label=f'Class {i}', edgecolors='k')\n\n# Plot testing points\nfor i, c in zip(range(3), ['maroon', 'orange', 'magenta']):\n    plt.scatter(X_test[y_test == i, 0], X_test[y_test == i, 1], c=c, marker='x', s=150, linewidth=2)\n\nplt.title('Naive Bayes Classifier - Iris Dataset')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 1.00\n\nConfusion Matrix:\n[[10  0  0]\n [ 0  9  0]\n [ 0  0 11]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      1.00      1.00         9\n           2       1.00      1.00      1.00        11\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-2.png){width=663 height=523}\n:::\n:::\n\n\nThis visualization demonstrates Naive Bayes Classifier in action on the Iris Dataset, with data points grouped into three classes.\n\n### 2. Logistic Regression\n\nBelow are the preview of the real-world Iris dataset with the following columns:\n\n-   Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm, Species\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#importing libraries \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\n\ndf= pd.read_csv(\"Iris.csv\")\ndf.drop(\"Id\",axis=1,inplace=True)    #droping id\ndf.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=126}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nsns.FacetGrid(df, hue=\"Species\", height=5).map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\").add_legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=598 height=471}\n:::\n:::\n\n\nThe plot shows the scatterplot by coloring species\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#let Create a pair plot of some columns \nsns.pairplot(df.iloc[:,:],hue='Species')  # graph also  tell us about the the realationship between the two columns\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=1093 height=947}\n:::\n:::\n\n\nThe plot shows the pair plot of the Iris dataset with main column feature by species\n\n### 3. **K-Nearest Neighbors (KNN)**\n\nThe aim is to identify the customer segments to whom the loan can be granted using the \"loan.csv\" dataset, below is the preview of the top five rows of the dataset:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#Importing the Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Reading the dataset\nloan_dataset = pd.read_csv(\"train_KNN_DT.csv\")\nloan_dataset.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=129}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loan_ID</th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Dependents</th>\n      <th>Education</th>\n      <th>Self_Employed</th>\n      <th>ApplicantIncome</th>\n      <th>CoapplicantIncome</th>\n      <th>LoanAmount</th>\n      <th>Loan_Amount_Term</th>\n      <th>Credit_History</th>\n      <th>Property_Area</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LP001002</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>5849</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LP001003</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4583</td>\n      <td>1508.0</td>\n      <td>128.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LP001005</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>3000</td>\n      <td>0.0</td>\n      <td>66.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LP001006</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2583</td>\n      <td>2358.0</td>\n      <td>120.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LP001008</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>6000</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nloan_dataset.isna().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=130}\n```\nLoan_ID               0\nGender               13\nMarried               3\nDependents           15\nEducation             0\nSelf_Employed        32\nApplicantIncome       0\nCoapplicantIncome     0\nLoanAmount           22\nLoan_Amount_Term     14\nCredit_History       50\nProperty_Area         0\nLoan_Status           0\ndtype: int64\n```\n:::\n:::\n\n\n#### 3.1 Dataset Feature Description\n\n-   **Loan_Id**: Each applicant is assigned a unique Loan_Id for individual identification purposes.\n\n-   **Gender**: This field indicates the gender of the applicant.\n\n-   **Married**: This field indicates whether the applicant is currently married.\n\n-   **Dependents**: This field signifies whether the applicant is financially dependent on someone else.\n\n-   **Education**: This field provides information about the educational status of the applicant.\n\n-   **Self_Employed**: This field indicates whether the applicant is self-employed.\n\n-   **ApplicantIncome**: This field denotes the income of the applicant.\n\n-   **CoApplicantIncome**: This field represents the income of the co-applicant, where a co-applicant is an individual applying jointly with the borrower for a loan.\n\n-   **Loan_Amount**: This field indicates the amount of the loan that the applicant borrows from the bank.\n\n-   **Loan_Amount_Term**: This field represents the term of the loan amount for each applicant. A term amount loan is characterized by a fixed amount and a predetermined repayment schedule, featuring either a fixed or floating interest rate.\n\n-   **Credit_History**: This field signifies the credit history of each applicant, documenting their responsible repayment of debts.\n\n-   **Loan_Status**: This field indicates whether the loan is approved or not, denoted by 'Y' for approved and 'N' for not approved.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nloan_dataset['Gender'] = loan_dataset['Gender'].fillna(loan_dataset['Gender'].mode().values[0])\nloan_dataset['Married'] = loan_dataset['Married'].fillna(loan_dataset['Married'].mode().values[0])\nloan_dataset['Dependents'] = loan_dataset['Dependents'].fillna(loan_dataset['Dependents'].mode().values[0])\nloan_dataset['Self_Employed'] = loan_dataset['Self_Employed'].fillna(loan_dataset['Self_Employed'].mode().values[0])\nloan_dataset['LoanAmount'] = loan_dataset['LoanAmount'].fillna(loan_dataset['LoanAmount'].mean())\nloan_dataset['Loan_Amount_Term'] = loan_dataset['Loan_Amount_Term'].fillna(loan_dataset['Loan_Amount_Term'].mode().values[0] )\nloan_dataset['Credit_History'] = loan_dataset['Credit_History'].fillna(loan_dataset['Credit_History'].mode().values[0] )\n# Drop the ID column\nloan_dataset.drop('Loan_ID', axis=1, inplace=True)\nloan_dataset.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=131}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Dependents</th>\n      <th>Education</th>\n      <th>Self_Employed</th>\n      <th>ApplicantIncome</th>\n      <th>CoapplicantIncome</th>\n      <th>LoanAmount</th>\n      <th>Loan_Amount_Term</th>\n      <th>Credit_History</th>\n      <th>Property_Area</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>5849</td>\n      <td>0.0</td>\n      <td>146.412162</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>4583</td>\n      <td>1508.0</td>\n      <td>128.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Rural</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>Yes</td>\n      <td>3000</td>\n      <td>0.0</td>\n      <td>66.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Not Graduate</td>\n      <td>No</td>\n      <td>2583</td>\n      <td>2358.0</td>\n      <td>120.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>Graduate</td>\n      <td>No</td>\n      <td>6000</td>\n      <td>0.0</td>\n      <td>141.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>Urban</td>\n      <td>Y</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\n```\n:::\n\n\n#### 3.2 Imputation of the Missing Values\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n#Convert some object data type to int\ngender = {\"Female\": 0, \"Male\": 1}\nyes_no = {'No' : 0,'Yes' : 1}\ndependents = {'0':0,'1':1,'2':2,'3+':3}\neducation = {'Not Graduate' : 0, 'Graduate' : 1}\nproperty = {'Semiurban' : 0, 'Urban' : 1,'Rural' : 2}\noutput = {\"N\": 0, \"Y\": 1}\n\nloan_dataset['Gender'] = loan_dataset['Gender'].replace(gender)\nloan_dataset['Married'] = loan_dataset['Married'].replace(yes_no)\nloan_dataset['Dependents'] = loan_dataset['Dependents'].replace(dependents)\nloan_dataset['Education'] = loan_dataset['Education'].replace(education)\nloan_dataset['Self_Employed'] = loan_dataset['Self_Employed'].replace(yes_no)\nloan_dataset['Property_Area'] = loan_dataset['Property_Area'].replace(property)\nloan_dataset['Loan_Status'] = loan_dataset['Loan_Status'].replace(output)\n\nloan_dataset.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=133}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Married</th>\n      <th>Dependents</th>\n      <th>Education</th>\n      <th>Self_Employed</th>\n      <th>ApplicantIncome</th>\n      <th>CoapplicantIncome</th>\n      <th>LoanAmount</th>\n      <th>Loan_Amount_Term</th>\n      <th>Credit_History</th>\n      <th>Property_Area</th>\n      <th>Loan_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5849</td>\n      <td>0.0</td>\n      <td>146.412162</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4583</td>\n      <td>1508.0</td>\n      <td>128.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3000</td>\n      <td>0.0</td>\n      <td>66.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2583</td>\n      <td>2358.0</td>\n      <td>120.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6000</td>\n      <td>0.0</td>\n      <td>141.000000</td>\n      <td>360.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Drop \"Loan_Status\" and assign it to target variable.\ny = loan_dataset.Loan_Status\nprint(y)\nx = loan_dataset.drop('Loan_Status', axis=1, inplace=False)\n\n#Splitting the dataset into train and test set\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.25, random_state=38, stratify = y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0      1\n1      0\n2      1\n3      1\n4      1\n      ..\n609    1\n610    1\n611    1\n612    1\n613    0\nName: Loan_Status, Length: 614, dtype: int64\n```\n:::\n:::\n\n\n#### 3.3 K Neighbors Classifier implementation\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train, Y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=135}\n```{=html}\n<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n##### 3.3.1 Prediction on the Test Set\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nprediction_knn = knn.predict(X_test)\nprint(\"Prediction for test set: {}\".format(prediction_knn))\nprint('Accuracy of the model: {:.2f}'.format(accuracy_score(Y_test, prediction_knn)*100))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPrediction for test set: [1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1\n 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n 1 1 1 0 1 1]\nAccuracy of the model: 65.58\n```\n:::\n:::\n\n\n##### 3.3.2 Actual values and the predicted values\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n#Actual value and the predicted value\ndiff_knn = pd.DataFrame({'Actual value': Y_test, 'Predicted value': prediction_knn})\ndiff_knn\n```\n\n::: {.cell-output .cell-output-display execution_count=137}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual value</th>\n      <th>Predicted value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>263</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>154 rows × 2 columns</p>\n</div>\n```\n:::\n:::\n\n\n##### 3.3.3 Evaluating the K Neighbors Classifier Model\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n#Confusion matrix and classification report\nfrom sklearn import metrics \nfrom sklearn.metrics import classification_report, confusion_matrix\ncon_mat = confusion_matrix(Y_test, prediction_knn)\nprint(con_mat)\n\nsns.heatmap(con_mat, annot=True, fmt=\"d\", cmap='YlGnBu')\nplt.title('Confusion Matrix for KNN')\nplt.xlabel('Predicted')\nplt.ylabel('True')\n\nprint(classification_report(Y_test, prediction_knn))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 9 39]\n [14 92]]\n              precision    recall  f1-score   support\n\n           0       0.39      0.19      0.25        48\n           1       0.70      0.87      0.78       106\n\n    accuracy                           0.66       154\n   macro avg       0.55      0.53      0.51       154\nweighted avg       0.61      0.66      0.61       154\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-2.png){width=547 height=449}\n:::\n:::\n\n\n### 4. Decision Tree\n\n### (implementation on the same dataset as the K-Neighbors Classifier)\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ndTree = tree.DecisionTreeClassifier()\ndTree.fit(X_train, Y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=139}\n```{=html}\n<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nprediction_dt = dTree.predict(X_test)\nprint(\"Prediction for test set: {}\".format(prediction_dt))\nprint('Accuracy of the model: {:.2f}'.format(accuracy_score(Y_test, prediction_dt)*100))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPrediction for test set: [1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0\n 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0\n 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1\n 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1\n 1 1 1 0 1 1]\nAccuracy of the model: 66.88\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n#Actual value and the predicted value\ndiff_dt = pd.DataFrame({'Actual value': Y_test, 'Predicted value': prediction_dt})\ndiff_dt\n```\n\n::: {.cell-output .cell-output-display execution_count=141}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual value</th>\n      <th>Predicted value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>263</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>154 rows × 2 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n#Confusion matrix and classification report\ncon_mat = confusion_matrix(Y_test, prediction_dt)\nprint(con_mat)\n\nsns.heatmap(con_mat, annot=True, fmt=\"d\", cmap='YlGnBu')\nplt.title('Confusion Matrix for Decision Tree')\nplt.xlabel('Predicted')\nplt.ylabel('True')\n\nprint(classification_report(Y_test, prediction_dt))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[17 31]\n [20 86]]\n              precision    recall  f1-score   support\n\n           0       0.46      0.35      0.40        48\n           1       0.74      0.81      0.77       106\n\n    accuracy                           0.67       154\n   macro avg       0.60      0.58      0.59       154\nweighted avg       0.65      0.67      0.66       154\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-21-output-2.png){width=547 height=449}\n:::\n:::\n\n\n### Results for the Load dataset by comparing both the K Neighbors and Decision Tree Classifiers\n\n**1. KNN:** KNN gve the accuracy of 65.58%.\n\n**2. Decision Tree:** Decision tree gave the accuracy of 67.53%.\n\n## Conclusion\n\nIn this blog post, we explored classification algorithms in machine learning, implemented them in Python, and visualized their decision boundaries. We used the Iris and Load datasets as examples and showcased popular classifiers like Naive Bayes, Logistic Regression, K-Nearest Neighbors, and Decision Tree.\n\nUnderstanding classification algorithms and their performance is crucial for building accurate machine learning models. Python's extensive libraries and visualization capabilities make it a powerful tool for this task. Experiment with different datasets and classifiers to gain a deeper understanding of classification in machine learning.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}